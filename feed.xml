<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://junoh-kang.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://junoh-kang.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-03-24T16:16:37+00:00</updated><id>https://junoh-kang.github.io/feed.xml</id><subtitle></subtitle><entry><title type="html">Video Diffusion Models as World Simulators</title><link href="https://junoh-kang.github.io/blog/2025/dl-Video-Diffusion-Models-as-World-Simulator/" rel="alternate" type="text/html" title="Video Diffusion Models as World Simulators"/><published>2025-01-17T00:00:00+00:00</published><updated>2025-01-17T00:00:00+00:00</updated><id>https://junoh-kang.github.io/blog/2025/dl:%20Video%20Diffusion%20Models%20as%20World%20Simulator</id><content type="html" xml:base="https://junoh-kang.github.io/blog/2025/dl-Video-Diffusion-Models-as-World-Simulator/"><![CDATA[<h2 id="overview">Overview</h2> <p><strong>World simulators</strong> are explorable and interactive systems or models that can mimic real world. Advanced video generation models can function as world simulators, and to achieve it, they should have <strong>low latency</strong> for input actions, and capable of <strong>long sequence generation</strong>. Long sequence generation includes <strong><u>capability of long generation itself</u></strong>, <strong><u>preventing error accumulation</u></strong>, and <strong><u>long term context preservation</u></strong>. This post mainly focuses on how related project <strong>Oasis: A Universe in a transformer</strong><d-cite key="decart2024oasis"></d-cite> deals with <strong>long sequence generation</strong>.</p> <hr/> <h2 id="conventional-long-video-generation-are-inappropriate-for-world-simulator">Conventional Long Video Generation are inappropriate for World Simulator!</h2> <h3 id="video-diffusion-models-vdms">Video Diffusion Models (VDMs)</h3> <table> <thead> <tr> <th style="text-align: left"><img src="/blog/post/20250117/1.vdm.png" alt="" style="margin:auto; display:block;width:90%; height:auto;"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Training and sampling of video diffusion models. Darker tokens has higher noise levels.</td> </tr> </tbody> </table> <p><strong><u>Videos are sequential data</u></strong>. However, video diffusion models are trained and inferenced to denoise tokens of same noise levels, interpreting each video clip as a single object. This section reviews approaches to generate long videos using aforementioned VDMs.</p> <h3 id="chunked-autoregressive-methods">Chunked autoregressive methods</h3> <table> <tbody> <tr> <td><img src="/blog/post/20250117/2.chunked.png" alt="" style="margin:auto; display:block;width:90%; height:auto;"/></td> </tr> </tbody> </table> <ul> <li>Small \(k\) (<em>e.g.</em> \(k=1\)) results in high latency for each action since \(f-k\) frames are output for each action. Also it tends to lose contexts.</li> <li>Large \(k\) (<em>e.g.</em> \(k=f-1\)) results in ineifficient training and inference since models learn only \(f-k\) tokens, while models calculate for \(f\) tokens.</li> <li>Chunked autoregressive methods suffers from <strong><u>quality degradation originated from error accumulation</u></strong>.</li> </ul> <table> <tbody> <tr> <td><img src="/blog/post/20250117/3.chunked_erroraccumulate.png" alt="" style="margin:auto; display:block;width:90%; height:auto;"/></td> </tr> </tbody> </table> <h3 id="hierarchical-methods-multi-stage-generation">Hierarchical methods (Multi-stage generation)</h3> <table> <tbody> <tr> <td><img src="/blog/post/20250117/4.hierarchy.png" alt="" style="margin:auto; display:block;width:90%; height:auto;"/></td> </tr> </tbody> </table> <ul> <li>It does not fit to interactive generation since the end of the video is already determined.</li> </ul> <p><strong>Conventional approaches are not appropriate for wolrd simulator!</strong></p> <table> <tbody> <tr> <td><img src="/blog/post/20250117/5.convention.png" alt="" style="margin:auto; display:block;width:90%; height:auto;"/></td> </tr> </tbody> </table> <hr/> <h2 id="long-sequence-generation-in-oasis">Long Sequence Generation in Oasis</h2> <h3 id="capability-of-long-sequence-generation">Capability of long sequence generation</h3> <p><strong>Oasis</strong><d-cite key="decart2024oasis"></d-cite> follows <strong>Diffusion Forcing</strong><d-cite key="chen2024diffusionforcing"></d-cite> to train models for long video generation. <strong>Diffusion Forcing</strong> inherits advantages of Teacher Forcing and Diffusion Models: <strong><u>flexible time horizon</u></strong> from Teacher Forcing, <strong><u>guidance at sampling</u></strong> from Diffusion Models.</p> <p><strong>Diffusion Forcing</strong> trains models to denoise <strong><u>tokens with independent noise levels</u></strong>, and sampling noise schedules are carefully chosen depending on the purpose. The training offers cheaper training than next-token prediction in video domain, and the complexity added by independent noise level is not excessive since the complexity is only in temporal dimension.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/blog/post/20250117/6.df_train.png" alt="" style="margin:auto; display:block;width:50%; height:auto;"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center">Training in Diffusion Forcing</td> </tr> </tbody> </table> <table> <thead> <tr> <th style="text-align: center"><img src="/blog/post/20250117/7.df_sample.png" alt="" style="margin:auto; display:block;width:90%; height:auto;"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center">Sampling in Diffusion Forcing</td> </tr> </tbody> </table> <h3 id="preventing-error-accumulation">Preventing error accumulation</h3> <h4 id="the-reason-of-error-accumulation">The reason of error accumulation</h4> <table> <tbody> <tr> <td><img src="/blog/post/20250117/8.vanilla.png" alt="" style="margin:auto; display:block;width:90%; height:auto;"/></td> </tr> </tbody> </table> <p><strong>Oasis</strong><d-cite key="decart2024oasis"></d-cite> and <strong>Diffusion Forcing</strong><d-cite key="chen2024diffusionforcing"></d-cite> hypothesize that the error accumulation stems from the model erroneously treating generated noisy frames as grount truth (GT), despite their inherent inaccuracies. They interpret <strong>input noise levels to the models as inversely proportional to the confidence</strong> in the corresponding input tokens.</p> <h4 id="stable-rollout-in-diffusion-forcing">Stable rollout in Diffusion Forcing</h4> <table> <tbody> <tr> <td><img src="/blog/post/20250117/9.stable_rollout.png" alt="" style="margin:auto; display:block;width:90%; height:auto;"/></td> </tr> </tbody> </table> <p><strong>Diffusion Forcing</strong> suggests to deceive models that generated clean tokens are little noisy, preventing models from believing generated tokens as GT. However, this approach is out of distribution (OOD) inference, and there is no rule of thumb for “little noisy”.</p> <h4 id="stable-rollout-another-option">Stable rollout (Another option)</h4> <table> <tbody> <tr> <td><img src="/blog/post/20250117/10.stable_rollout.png" alt="" style="margin:auto; display:block;width:90%; height:auto;"/></td> </tr> </tbody> </table> <p>To avoid OOD, one may suggest add little noise to generated tokens and tell models that the tokens are noisy. However, this approach may dilute details in generated tokens.</p> <h4 id="dynamic-noise-augmentation-dna">Dynamic Noise Augmentation (DNA)</h4> <table> <tbody> <tr> <td><img src="/blog/post/20250117/11.DNA.png" alt="" style="margin:auto; display:block;width:90%; height:auto;"/></td> </tr> </tbody> </table> <p><strong>Oasis</strong><d-cite key="decart2024oasis"></d-cite> suggests Dynamic Noise Augmentation (DNA) to mitigate error accumulation.</p> <ul> <li>For initial denoising steps, conditioning tokens (generated tokens) are moderately noised since models tend to generate low-frequency features during initial steps.</li> <li>For last denoising steps, noise levels of conditioning tokens gradually decreases.</li> </ul> <h3 id="long-term-context-preservation">Long term context preservation</h3> <table> <tbody> <tr> <td><img src="/blog/post/20250117/12.video.gif" alt="" style="margin:auto; display:block;width:50%; height:auto;"/></td> </tr> </tbody> </table> <p>Through above approaches, <strong>Oasis</strong> can autoregressively generate long videos without much quality degradation. However, models do not have long time horizon memory, leading to inconsistent videos. While there is no innovative breakthrough yet, I believe that video models with long-term memory is an important next step.</p>]]></content><author><name>Junoh Kang</name></author><category term="deep-learning"/><category term="paper-review,"/><summary type="html"><![CDATA[A review of Oasis: A Universe in a transformer, and Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion]]></summary></entry><entry><title type="html">Controllabilities in Video Diffusion Models</title><link href="https://junoh-kang.github.io/blog/2024/dl-Controllabilities-in-Video-Diffusion-Models/" rel="alternate" type="text/html" title="Controllabilities in Video Diffusion Models"/><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://junoh-kang.github.io/blog/2024/dl:%20Controllabilities%20in%20Video%20Diffusion%20Models</id><content type="html" xml:base="https://junoh-kang.github.io/blog/2024/dl-Controllabilities-in-Video-Diffusion-Models/"><![CDATA[<p>This presentation file includs videos. You may use pdf viewer that supports video playing such as Adobe Acrobat reader.</p>]]></content><author><name>Junoh Kang</name></author><category term="deep-learning"/><category term="paper-review,"/><summary type="html"><![CDATA[A review of papers that add controllabilities to video generation (DragNUWA and Boximator)]]></summary></entry><entry><title type="html">Designing Diffusion Models in Real World</title><link href="https://junoh-kang.github.io/blog/2023/dl-Designing-Diffusion-Models-in-Real-World/" rel="alternate" type="text/html" title="Designing Diffusion Models in Real World"/><published>2023-10-26T00:00:00+00:00</published><updated>2023-10-26T00:00:00+00:00</updated><id>https://junoh-kang.github.io/blog/2023/dl:%20Designing%20Diffusion%20Models%20in%20Real%20World</id><content type="html" xml:base="https://junoh-kang.github.io/blog/2023/dl-Designing-Diffusion-Models-in-Real-World/"><![CDATA[<h2 id="overview">Overview</h2> <p>In deep learning, practical implementations are just as important as theoretical supports. Especially when proposing new paradigms, such as GANs, diffusion models, and transformers, <em>etc.</em>, engineering skills are essential to bring the paradigms into the real world. Even if the suggested designs on diffusion models in <strong>Elucidating the Design Space of Diffusion-Based Generative Models (EDM)</strong><d-cite key="karras2022elucidating"></d-cite> are not optimal, the choices of the designs are theoretically or empirically supported. Learning these reasonings may help to bring your theory into the real world.</p> <hr/> <h2 id="revisit-diffusion-models">Revisit Diffusion Models</h2> <h3 id="reformulate-diffusion-models">Reformulate diffusion models</h3> <p><strong>Score-Based Model</strong><d-cite key="song2021scorebased"></d-cite> defines forward SDE and marginal distribution is calculated from forward SDE. However when it comes to training, marginal distribution is more important than the SDE and therefore <strong>EDM</strong><d-cite key="karras2022elucidating"></d-cite> defines the marginal distribution first.</p> \[\begin{align} p_t(\mathrm{x}) = s(t)^{-d}p(\mathrm{x} /s(t);\sigma(t)), \end{align}\] <p>where \(p(\mathrm{x};\sigma) = \left[p_{\text{data}} * \mathcal{N}(\mathrm{0}, \sigma^2\mathrm{I})\right](\mathrm{x})\).</p> <p>Then, the corresponding probability flow ODE is</p> \[\begin{align} d\mathrm{x} = \left[\dot{s}(t)/s(t) - s(t)^2 \dot{\sigma}(t)\sigma(t) \nabla_\mathrm{x} \log p(\mathrm{x}_t/s(t);\sigma(t)) \right] dt. \label{edm:ode} \end{align}\] <h3 id="obstacles-in-diffusion-models">Obstacles in diffusion models</h3> <p>Generation by diffusion models can interpreted as solving ODE:</p> \[\begin{align} d\mathrm{x} = f(\mathrm{x}_t, s(t), \sigma(t))dt. \end{align}\] <ol> <li> <p>\(f(\mathrm{x}_t, s(t), \sigma(t))\) is not known and it is parametrized by a network \(f_\theta(\mathrm{x}_t, s(t), \sigma(t))\). The inaccurate approximation on the target causes degradation. <br/> <strong>→ Better training!</strong></p> </li> <li> <p>The solution at \(t=0\) given boundary condition at \(t=T\) is <br/> \(\begin{align} \mathrm{x}_0 = \mathrm{x}_T + \int_0^T f(\mathrm{x}_t, s(t), \sigma(t))dt. \end{align}\) The integral is numerically calculated, which causes truncation errors. <br/> <strong>→ Reduce truncation errors, focus on important region!</strong></p> </li> </ol> <h3 id="design-space-of-diffusion-models">Design space of diffusion models</h3> <h4 id="components-regarding-training">Components regarding training</h4> <ul> <li>Parametrization and network preconditioning: \(c_\text{skip}(\sigma)\), \(c_\text{out}(\sigma)\), \(c_\text{in}(\sigma)\), \(c_\text{noise}(\sigma)\).</li> <li>Loss weighting: \(\lambda(t)\).</li> <li>Noise level distribution for training: \(\sigma \sim p_{\text{noise}}\).</li> <li>Augmentation</li> </ul> <h4 id="components-regarding-deterministic-sampling">Components regarding deterministic sampling</h4> <ul> <li>Truncation-error-reducing ODE: \(s(t)\), \(\sigma(t)\).</li> <li>Truncation-error-reducing algorithms: Higher-roder integrators</li> <li>Distributing truncation errors properly: Discretization \(\{t_i\}_0^N\)</li> </ul> <h4 id="components-regarding-stochastic-sampling">Components regarding stochastic sampling</h4> <ul> <li>Rate of replaced noises: \(\beta(t)\)</li> <li>Heuristics: \(S_{\text{tmin}}, S_{\text{tmax}}, S_{\text{noise}}, S_{\text{churn}}\).</li> </ul> <hr/> <h2 id="improvements-to-training">Improvements to Training</h2> <p>For this section, this post assumes \(s(t)=1\).</p> <h3 id="parametrization-network-preconditioning-loss-weighting">Parametrization, network preconditioning, loss weighting</h3> <p>\(D(\mathrm{x}_t,\sigma)\) is a denoiser which minimizes \(\ell_2\)-norm with \(\mathrm{y}\): \(\begin{align} \mathbb{E}_{\mathrm{y} \sim p_{\text{data}}} \mathbb{E}||D(\mathrm{y} + \mathrm{n}) - \mathrm{y}||_2^2. \label{eq:loss} \end{align}\)</p> <p>Then, the relation between a score function and the ideal denoiser is \(\begin{align} \nabla_{\mathrm{x}} \log p(\mathrm{x};\sigma) = (D(\mathrm{x};\sigma) - \mathrm{x}) / \sigma^2. \end{align}\)</p> <p>Networks in many baselines predicts either \(D(\mathrm{x},\sigma)\) or \(\mathrm{n}\). However, <strong>Dynamic dual-output diffusion models</strong><d-cite key="benny2022dynamic"></d-cite> observes that predicting \(D(\mathrm{x},\sigma)\) is easier for high noise level, while predicting \(\mathrm{n}\) is easier for low noise level.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/blog/post/20231026/benny.png" alt="" style="margin:auto; display:block;width:60%; height:auto;"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center">Loss comparison between predicting the denoised output or the added noise.</td> </tr> </tbody> </table> <p>From the observation, <strong>EDM</strong><d-cite key="karras2022elucidating"></d-cite> designs the network to predict \(D(\mathrm{x};\sigma)\) or \(\mathrm{n}\), or something in between according to the noise level. \(\begin{align} D_\theta(\mathrm{x};\sigma) = c_{\text{skip}}(\sigma)\mathrm{x} + c_{\text{out}}(\sigma) F_\theta(c_{\text{in}}(\sigma)\mathrm{x}; c_{\text{noise}}(\sigma)), \end{align}\) where \(F_\theta\) is a neural network.</p> <p>Then the loss function (\ref{eq:loss}) is \(\begin{align} \mathbb{E}_{\sigma,\mathrm{y},\mathbf{b}}\left[ \underbrace{\lambda(\sigma)c_{\text{out}}(\sigma)^2}_{\text{effective weight}} ||\underbrace{F_\theta(c_{\text{in}}(\sigma)(\mathrm{y}+\mathbf{n};c_{\text{noise}}(\sigma)))}_{\text{network output}} - \underbrace{\frac{1}{c_{\text{out}}(\sigma)}(\mathrm{y} - c_{\text{skip}}(\sigma)(\mathrm{y}+\textbf{n}))}_{\text{effective training target}}||_2^2 \right]. \end{align}\)</p> <h4 id="1network-inputs-should-have-bounded-range">1.Network inputs should have bounded range</h4> <p>\(\begin{align} \Rightarrow &amp;\text{Var}_{\mathrm{y},\mathbf{n}}\left[c_{\text{in}}(\sigma)(\mathrm{y} + \mathbf{n})\right] = 1 \\ \Rightarrow &amp;c_{\text{in}}(\sigma) = 1 / \sqrt{\sigma^2 + \sigma_{\text{data}}^2}\\ \text{&amp; } &amp;c_{\text{noise}}(\sigma) = \log (\sigma)/4 \end{align}\)</p> <h4 id="2effective-training-target-should-have-bounded-range">2.Effective training target should have bounded range</h4> <p>\(\begin{align} &amp;\Rightarrow \text{Var}_{\mathrm{y},\mathbf{n}}\left[\frac{1}{c_{\text{out}}(\sigma)}(\mathrm{y} - c_{\text{skip}}(\sigma)(\mathrm{y}+\textbf{n}))\right] = 1 \\ &amp;\Rightarrow c_{\text{out}}(\sigma)^2 = (1-c_{\text{skip}}(\sigma))^2\sigma_{\text{data}}^2 + c_{\text{skip}}(\sigma)^2 \sigma^2 \end{align}\)</p> <h4 id="3errors-of-network-should-not-be-amplified">3.Errors of network should not be amplified</h4> <p>\(\begin{align} \Rightarrow~ &amp;c_{\text{skip}}(\sigma) = \underset{c_{\text{skip}}(\sigma)}{\text{argmin}} ~c_{\text{out}}(\sigma) \\ \Rightarrow~ &amp;\begin{cases} c_{\text{skip}}(\sigma) = \sigma_{\text{data}}^2 / (\sigma^2 + \sigma_{\text{data}}^2) \\ c_{\text{out}}(\sigma) = \sigma \cdot \sigma_{\text{data}} / \sqrt{\sigma^2 + \sigma_{\text{data}}^2} \end{cases} \end{align}\)</p> <h4 id="4-effecitve-weight-should-be-uniform">4. Effecitve weight should be uniform</h4> <p>\(\begin{align} \Rightarrow~ &amp;\lambda(\sigma)c_{\text{out}}(\sigma)^2 = 1 \\ \Rightarrow~ &amp; \lambda(\sigma) = (\sigma^2 + \sigma_{\text{data}}^2)/(\sigma \cdot \sigma_{\text{data}})^2 \end{align}\)</p> <p>Putting 1 ~ 4 together, the expected value of the loss at each noise level is 1. Moreover, the change of effective training target according to \(\sigma\) coincides to the observation of <strong>Dynamic dual-output diffusion models</strong><d-cite key="benny2022dynamic"></d-cite>.</p> <h3 id="noise-level-distribution-for-training">Noise level distribution for training</h3> <table> <thead> <tr> <th style="text-align: left"><img src="/blog/post/20231026/edm_f5a.png" alt="" style="margin:auto; display:block; width:90%; height:auto;"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Observed loss per noise level. The shaded regions represent the standard deviation over 10k random samples. EDM’s proposed training sample density is shown by the dashed red curve.</td> </tr> </tbody> </table> <p>At low noise levels, seperating the small noise components is difficult and irrelevant, whereas at high noise levels, the correct answer approaches to dataset average; <strong>EDM</strong><d-cite key="karras2022elucidating"></d-cite> focuses on middle range noise levels for training: \(\sigma \sim \mathcal{N}(-1.2, 1.2)\).</p> <h3 id="augmentataion">Augmentataion</h3> <p><strong>EDM</strong><d-cite key="karras2022elucidating"></d-cite> follows the augmentation pipiline from the GAN literature<d-cite key="karras2020training"></d-cite>. <img src="/blog/post/20231026/edm_t6.png" alt="" style="margin:auto; display:block; width:90%; height:auto;"/></p> <ol> <li>Each agmentation is enabled with \(A_{\text{prob}}\).</li> <li>Draw \(a_i\) from each enabled augmentation and construct transformation matrix.</li> <li>Pass data through \(2\times\) supersampled high-quality Wavelet filters.</li> <li>Construct a 9-dimensional conditioning input vector for non-leaking augmentation. This vector makes the network to perform auxiliarty tasks.</li> </ol> <hr/> <h2 id="improvements-to-deterministic-sampling">Improvements to Deterministic Sampling</h2> <h3 id="higher-order-integrators">Higher-order integrators</h3> <p>For \(s(t)=1\) and \(\sigma(t)=t\), the ODE to solve is</p> \[\begin{align} d\mathrm{x}/dt = (\mathrm{x}_t - D(\mathrm{x}_t;t))/t := f(\mathrm{x}_t,t). \end{align}\] <h4 id="euler-method"><a href="https://en.wikipedia.org/wiki/Euler_method"><em>Euler method</em></a></h4> <p>Euler method approximates the integral by</p> \[\begin{align} \int_{t_{i}}^{t_{i-1}} f(\mathrm{x}_t,t) dt = (t_{i-1} - t_{i})f(\mathrm{x}_{t_i},t_i) + O(|t_{i-1}-t_{i}|^2). \end{align}\] <p>Therefore, the total truncation error is \(O(\max \lvert t_{i-1}-t_{i} \rvert)\). Let \(\hat{\mathrm{x}}_{t_{i-1}}\) is a solution obtained by Euler method.</p> <h4 id="heuns-method"><a href="https://en.wikipedia.org/wiki/Heun%27s_method"><em>Heun’s method</em></a></h4> <p>Then, Heun’s method approximates the integral by</p> \[\begin{align} \int_{t_{i}}^{t_{i-1}} f(\mathrm{x}_t,t) dt = (t_{i-1} - t_{i})(f(\mathrm{x}_{t_i},t_i)+ f(\hat{\mathrm{x}}_{t_{i-1}},t_{i-1}))/2+ O(|t_{i-1}-t_{i}|^3). \end{align}\] <p>Therefore, the total truncation error is \(O(\max{\lvert t_{i-1}-t_{i}|^2 \rvert})\). Huen’s method decreases truncation error at the cost of one additional evaluation of the network.</p> <h4 id="deterministic-sampling-algorithm-for-edm">Deterministic sampling algorithm for <strong>EDM</strong><d-cite key="karras2022elucidating"></d-cite></h4> <p><img src="/blog/post/20231026/edm_a1.png" alt="" style="margin:auto; display:block; width:100%; height:auto;"/></p> <h3 id="discretization">Discretization</h3> <p>As long as using numerical integrators with limited computational resources, <strong>truncation errors are inevitable</strong>. In terms of obtaining ODE trajectories accurately, it is important to minimize total truncation erros. Hoever, the interests of diffusion models at generation are only the <strong>solutions at low noise levels</strong>; it is reasonable to <strong>focus on low noise levels</strong>. EDM discretizes as</p> \[\begin{align} t_{N-i} = \sigma_{i&lt; N} = (\sigma_{\text{max}}^{1/\rho} + \frac{i}{N-1} (\sigma_{\text{min}}^{1/\rho} - \sigma_{\text{max}}^{1/\rho}))^\rho, \sigma_N = 0. \end{align}\] <p>Increasing \(\rho\) results dense discretizations at low noise levels.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/blog/post/20231026/edm_f12.png" alt="" style="margin:auto; display:block; width:100%; height:auto;"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center">(a),(b) Local truncation error at different noise levels. (c) FID as a function of \(\rho\).</td> </tr> </tbody> </table> <p>\(\rho=3\) nearly equalizes the truncation error at each step as in (a), (b). On the other hand, \(\rho=7\) generates better samples as in (c). Proper value of \(\rho\) changes according to the tasks. <em>e.g.</em>, equalized truncation error will be better for solving ODE in both directions.</p> <h3 id="truncation-error-reducing-ode">Truncation-error-reducing ODE</h3> <p>Many integrators including Euler and Heun’s method have small truncation errors if \(f(\mathrm{x}_t,t)\) has <strong>small curvature</strong>, or is close to linear function. \(s(t)\) and \(\sigma(t)\) determine the shape of the ODE solution trajectories, which is closely related to linearity of the \(f(\cdot)\).</p> \[\int_{t_{i}}^{t_{i-1}} f(\mathrm{x}_t,t) dt \approx \begin{cases} (t_{i-1} - t_{i})f(\mathrm{x}_{t_i},t_i) &amp; \text{Euler method} \\ (t_{i-1} - t_{i}) (f(\mathrm{x}_{t_i},t_i)+ f(\hat{\mathrm{x}}_{t_{i-1}},t_{i-1}))/2 &amp; \text{Heun's method} \end{cases}\] <table> <thead> <tr> <th style="text-align: left"><img src="/blog/post/20231026/edm_f3.png" alt="" style="margin:auto; display:block; width:100%; height:auto;"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: left">A sketch of ODE curvature in 1D where \(p_{\text{data}}\) is two Dirac peaks at \(\mathrm{x}= \pm 1\). Axis is chosen to show \(\sigma \in [0,25]\) and zoom in \(\sigma \in [0,1]\). (c) sketches the curvature when \(s(t)=1\) and \(\sigma(t)=t\). It has small curvature, while the tangent directs to the datapoints.</td> </tr> </tbody> </table> <h3 id="results-of-deterministic-sampling">Results of deterministic sampling</h3> <p><img src="/blog/post/20231026/edm_t2.png" alt="" style="margin:auto; display:block; width:100%; height:auto;"/></p> <ul> <li>Config B changes basic hyperparameters such as batch size, learning rate, dropout, <em>etc</em>; it disable gradient clipping</li> <li>Config C improves the expressive power of the model.</li> <li>Configs D, E, and F are explained in the previous context.</li> </ul> <hr/> <h2 id="stochastic-sampling">Stochastic Sampling</h2> <h3 id="sde-formulation">SDE formulation</h3> <p><strong>EDM</strong><d-cite key="karras2022elucidating"></d-cite> reformulates forward and backward SDE as a sum of the probability flow ODE and a varying-rate <a href="https://en.wikipedia.org/wiki/Langevin_dynamics"><em>Langevin diffusion</em></a> SDE: \(\begin{align} d\mathrm{x}_{\pm} = \underbrace{-\dot{\sigma}(t)\sigma(t) \nabla_\mathrm{x} \log p(\mathrm{x};\sigma(t)) dt}_{\text{probability flow ODE}} \pm \underbrace{\underbrace{\beta(t)\sigma(t)^2 \nabla_\mathrm{x} \log p(\mathrm{x};\sigma(t)) dt}_{\text{deterministic noise decay}} + \underbrace{\sqrt{2\beta(t)}\sigma(t) d\mathrm{w}_t}_{\text{noise injection}}}_{\text{Langevin diffusion SDE}} \end{align}\)</p> <h4 id="role-of-stochasticity">Role of stochasticity</h4> <p>In theory, ODE and SDE have the same marginal distributions. However in practice, stochasticity in sampling often enhances the sample quality. The authors attribute the beneficial role of stochasticity to the following steps:</p> <ol> <li>\(\mathrm{x}_t\) deviates from the ideal marginal distribution, due to the training and truncation errors.</li> <li>The <em>Langevin diffusion</em> drives the sample towards the ideal marginal distribution.</li> </ol> <h4 id="stochastic-sampling-algorithm-in-edm">Stochastic sampling algorithm in EDM</h4> <p><img src="/blog/post/20231026/edm_a2.png" alt="" style="margin:auto; display:block; width:100%; height:auto;"/></p> <p>Stochastic sampling algorithm in <strong>EDM</strong><d-cite key="karras2022elucidating"></d-cite> is executed in two steps:</p> <ol> <li><strong>Noise injection</strong>: integrate noise into samples according to \(\gamma_i \geq 0\).</li> <li><strong>Noise decay with probability flow</strong>: solve the ODE from increased noise level to desired level.</li> </ol> <h3 id="algorithm-in-real-world">Algorithm in real world</h3> <table> <thead> <tr> <th style="text-align: left"><img src="/blog/post/20231026/edm_f13.png" alt="" style="margin:auto; display:block; width:100%; height:auto;"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Observe the effect of <em>Langevin diffusion</em> in real world: there is gradual image degradation with the repeated addition and removal of noise. A random image is drawn from \(p(\mathrm{x};\sigma)\) and Algorithm 2 is run for a certain number of steps with \(\gamma_i=\sqrt{2}-1\).</td> </tr> </tbody> </table> <p><em>Langevin diffusion</em> is supposed to drive the sample towards the true data distribution, however…</p> <ul> <li>For low noise levels, images drift toward <strong>oversaturated colors</strong>.</li> <li>For high noise levels, images become abstract when \(s_{\text{noise}}=1\).</li> </ul> <p>Authors suspect that <strong>non-conservative vector field</strong> generated by parametrized denoiser <strong>violates the premises of Langevin diffusion</strong> since their analytical denoisers have not shown such degradation.</p> <p>\(\Rightarrow\) Fix flaws of \(D_\theta(\mathrm{x};\sigma)\) with heuristics!</p> <ul> <li> <p>For low noise levels, images drift toward <strong>oversaturated colors</strong>.<br/> \(\Rightarrow\) Enable stochasticity within \(t_i \in [S_{\text{tmin}}, \underline{S_{\text{tmax}}}]\).</p> </li> <li> <p>For high noise levels, images become <strong>abstract</strong> when \(S_{\text{noise}}=1\). <br/> \(\Rightarrow\) \(D_\theta(\cdot)\) removes too much noise because of <a href="https://en.wikipedia.org/wiki/Regression_toward_the_mean"><em>regression towards the mean</em></a>, which often happens when \(\ell_2\) trained.<br/> \(\Rightarrow\) Inflate the standard deviation of newly added noise: \(S_{\text{noise}}&gt;1\).</p> </li> <li> <p>New noise never exceeds the noise already in the image. <br/> \(\Rightarrow\) Clamp \(\gamma_i\).</p> </li> <li> <p>Controls the overal stochasticity by \(S_{\text{churn}}\).</p> </li> </ul> <h3 id="results-of-stochastic-sampling">Results of stochastic sampling</h3> <table> <thead> <tr> <th style="text-align: left"><img src="/blog/post/20231026/edm_f4.png" alt="" style="margin:auto; display:block; width:100%; height:auto;"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Evaluation of stochastic samplers with ablations. Red line is deterministic sampler while purple line is optimal stochastic sampler.</td> </tr> </tbody> </table>]]></content><author><name>Junoh Kang</name></author><category term="deep-learning"/><category term="paper-review,"/><summary type="html"><![CDATA[A review of a paper, Elucidating the Design Space of Diffusion-Based Generative Models. This post focuses on the reasons of the engineering details in the paper.]]></summary></entry><entry><title type="html">Understanding Diffusion Models in Two Perspectives</title><link href="https://junoh-kang.github.io/blog/2023/dl-Understanding-Diffusion-Models-in-Two-Perspectives/" rel="alternate" type="text/html" title="Understanding Diffusion Models in Two Perspectives"/><published>2023-09-03T00:00:00+00:00</published><updated>2023-09-03T00:00:00+00:00</updated><id>https://junoh-kang.github.io/blog/2023/dl%20:%20Understanding%20Diffusion%20Models%20in%20Two%20Perspectives</id><content type="html" xml:base="https://junoh-kang.github.io/blog/2023/dl-Understanding-Diffusion-Models-in-Two-Perspectives/"><![CDATA[<h2 id="overview">Overview</h2> <p><strong>DDPM</strong><d-cite key="ho2020denoising"></d-cite> and <strong>Score-Based Model</strong><d-cite key="song2021scorebased"></d-cite> introduce diffusion model as a new paradigm of generative models. Since the concepts of both papers are similar, one might regard <strong>Score-Based Model</strong><d-cite key="song2021scorebased"></d-cite> as only a continuous version of <strong>DDPM</strong><d-cite key="ho2020denoising"></d-cite>. Two papers have slight different views, even their loss functions and implementations are similar.</p> <p>This post mainly explains how formulations and objectives of two papers are different, and how they are related even with the differences.</p> <h4 id="summary-of-the-post">Summary of the post</h4> <ol> <li>The objective of <strong>DDPM</strong><d-cite key="ho2020denoising"></d-cite> is to minimize the surrogate of the negative log-likelihood.</li> <li>The objective of <strong>Score-Based Model</strong><d-cite key="song2021scorebased"></d-cite> is to match marginal distributions of forward SDE and backward SDE/ODE.</li> <li>Even with the differences, both derivations require the score function, differential of the log of the probability density function. The score functions are parametrized by neural networks and both papaers have similar loss functions.</li> </ol> <hr/> <h2 id="maximizing-log-likelihood">Maximizing Log-Likelihood</h2> <h3 id="forward-diffusion-process">Forward (Diffusion) Process</h3> <p>The forward process is a Markov chain that gradually adds Gaussian noise to the data for \(T\) steps with distributions defined as follows: \(\begin{align} &amp;\mathrm{x}_t \perp\mkern-9.5mu\perp \mathrm{x}_{0:t-1}, \\ &amp;q(\mathrm{x}_0) := \mathrm{P}_{data}(\mathrm{x}_0), \\ &amp;q(\mathrm{x}_t|\mathrm{x}_{t-1}) := \mathcal{N}(\mathrm{x}_t;\sqrt{1-\beta_t}\mathrm{x}_{t-1}, \beta_t \mathrm{I}), \end{align}\)</p> <p>where \(\{\beta_t\}_{t=1}^T\) are pre-defined constants.</p> <h3 id="backward-denoising-process">Backward (Denoising) Process</h3> <p>The backward process is a Markov chain that gradually denoises perturbed data and it is parametrized by neural networks. When \(\beta_t\ll 1\) the backward distribution can be approximated as \(\begin{align} q(\mathrm{x}_{t-1}|\mathrm{x}_{t}) \approx \mathcal{N}(\mathrm{x}_{t-1}; \cfrac{1}{ \sqrt{1-\beta_t}}(\mathrm{x}_{t} + \beta_t \nabla \log q (\mathrm{x}_t)), \beta_t \mathrm{I}). \end{align}\)</p> <details><summary><em>proof.</em></summary> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/blog/post/20230903/proof-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/blog/post/20230903/proof-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/blog/post/20230903/proof-1400.webp"/> <img src="/blog/post/20230903/proof.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </details> <p>It is reasonable to parametrize the denoising distribution as Gaussian as long as \(\{\beta_t\}_{t=1}^T\) are infinitesimal. Therefore the bacward process is defined as follows: \(\begin{align} &amp;\mathrm{x}_t \perp\mkern-9.5mu\perp \mathrm{x}_{t+1:T}, \\ &amp;p(\mathrm{x}_T) := \mathcal{N}(\mathrm{x}_T; \mathrm{0}, \mathrm{I}) \\ &amp;p(\mathrm{x}_{t-1}|\mathrm{x}_{t}) = \mathcal{N}(\mathrm{x}_{t-1}; \cfrac{1}{ \sqrt{1-\beta_t}}(\mathrm{x}_{t} + \beta_t s_\theta(\mathrm{x}_t,t)), \beta_t \mathrm{I}), \end{align}\)</p> <p>Note that we expect \(s_\theta(\mathrm{x}_t,t)\) to learn \(\nabla\log q(\mathrm{x}_t)\).</p> <h3 id="minimizing-surrogate-of-negative-log-likelihood">Minimizing Surrogate of Negative Log-Likelihood</h3> <p>The negative log-likelihood of data is \(\begin{align} \mathbb{E}_{\mathrm{x}_0 \sim q} \left[-\log p(\mathrm{x}_0)\right] &amp;\leq \mathbb{E}_{\mathrm{x}_0 \sim q} \mathbb{E}_{\mathrm{x}_{1:T|0} \sim q} \left[ \log \cfrac{q(\mathrm{x}_{1:T}|\mathrm{x}_{0})}{p(\mathrm{x}_{0:T})} \right]. \end{align}\)</p> <details><summary><em>proof.</em></summary> \[\begin{align*} -\log p(\mathrm{x}_0) &amp;= -\log \int p(\mathrm{x}_{0:T}) d\mathrm{x}_{1:T} \\ &amp;= -\log \int q(\mathrm{x}_{1:T}|\mathrm{x}_{0}) \cfrac{p(\mathrm{x}_{0:T})}{q(\mathrm{x}_{1:T}|\mathrm{x}_{0})} d\mathrm{x}_{1:T} \\ &amp;\leq -\int q(\mathrm{x}_{1:T}|\mathrm{x}_{0}) \log \cfrac{p(\mathrm{x}_{0:T})}{q(\mathrm{x}_{1:T}|\mathrm{x}_{0})} d\mathrm{x}_{1:T} ~~(\because \text{Jensen})\\ &amp;= \mathbb{E}_{\mathrm{x}_{1:T|0} \sim q} \left[ \log \cfrac{q(\mathrm{x}_{1:T}|\mathrm{x}_{0})}{p(\mathrm{x}_{0:T})} \right]. \end{align*}\] </details> <p>Using Markov properties, \(\begin{align} &amp;q(\mathrm{x}_{1:T} | \mathrm{x}_0) = q(\mathrm{x}_T | \mathrm{x}_0) \prod_{t=2}^T q(\mathrm{x}_{t-1} | \mathrm{x}_t, \mathrm{x}_0), \\ &amp;p(\mathrm{x}_{T:0}) = p(\mathrm{x}_T) \prod_{t=T}^{1} p(\mathrm{x}_{t-1}|\mathrm{x}_t). \end{align}\)</p> <details><summary><em>proof.</em></summary> \[\begin{align*} q(\mathrm{x}_{1:T} | \mathrm{x}_0) &amp;= \prod_{t=1}^{T} q(\mathrm{x}_{t}|\mathrm{x}_{0:t-1}) \\ &amp;= \prod_{t=1}^{T} q(\mathrm{x}_{t}|\mathrm{x}_{t-1}) \\ &amp;= q(\mathrm{x}_1|\mathrm{x}_0)\prod_{t=2}^{T} q(\mathrm{x}_{t}|\mathrm{x}_{t-1}, \mathrm{x}_{0}) \\ &amp;= q(\mathrm{x}_1|\mathrm{x}_0)\prod_{t=2}^{T} \frac{q(\mathrm{x}_{t},\mathrm{x}_{t-1}| \mathrm{x}_{0})}{q(\mathrm{x}_{t-1}| \mathrm{x}_{0})} \\ &amp;= q(\mathrm{x}_1|\mathrm{x}_0)\prod_{t=2}^{T} \frac{q(\mathrm{x}_{t}|\mathrm{x}_{0})q(\mathrm{x}_{t-1}| \mathrm{x}_{t},\mathrm{x}_{0})}{q(\mathrm{x}_{t-1}| \mathrm{x}_{0})} \\ &amp;= q(\mathrm{x}_T | \mathrm{x}_0) \prod_{t=2}^T q(\mathrm{x}_{t-1} | \mathrm{x}_t, \mathrm{x}_0), \\ p(\mathrm{x}_{T:0}) &amp;= p(\mathrm{x}_T) \prod_{t=T}^{1} p(\mathrm{x}_{t-1}|\mathrm{x}_{T:t})\\ &amp;= p(\mathrm{x}_T) \prod_{t=T}^{1} p(\mathrm{x}_{t-1}|\mathrm{x}_t). \end{align*}\] </details> <p>Therefore, the surrogate of negative log-likelihood becomes \(\begin{align} &amp;D_{KL}(q(\mathrm{x}_T|\mathrm{x}_0) || p(\mathrm{x}_T)) + \mathbb{E}_q\left[-\log p(\mathrm{x}_0|\mathrm{x}_1)\right] \nonumber \\ &amp;+ \sum_{t=2}^T D_{KL}(q(\mathrm{x}_{t-1} | \mathrm{x}_t, \mathrm{x}_0) || p(\mathrm{x}_{t-1}|\mathrm{x}_t)). \end{align}\)</p> <p>The surrogate of negative log-likelihood can be explictly expressed using \(\begin{align} &amp;p(\mathrm{x}_{t-1}|\mathrm{x}_{t}) = \mathcal{N}(\mathrm{x}_{t-1}; \cfrac{1}{ \sqrt{1-\beta_t}}(\mathrm{x}_{t} + \beta_t s_\theta(\mathrm{x}_t,t)), \beta_t \mathrm{I}), \\ &amp;q(\mathrm{x}_{t-1}|\mathrm{x}_{t}, \mathrm{x}_{0}) = \mathcal{N}(\mathrm{x}_{t-1}; \cfrac{1}{ \sqrt{1-\beta_t}}(\mathrm{x}_{t} + \beta_t \nabla \log q (\mathrm{x}_t|\mathrm{x}_{0})), \frac{1-\bar\alpha_{t-1}}{1-\bar\alpha_t}\beta_t \mathrm{I}), \end{align}\)</p> <p>where \(\bar\alpha_t = \prod_{s=1}^t (1-\beta_s)\).</p> <p>Finally, the objective function becomes \(\begin{align} \sum_{t=1}^T \mathbb{E}_{\mathrm{x}_0}\mathbb{E}_{\mathrm{x}_{t}|\mathrm{x}_{0}} \left[ \lambda_t ||s_\theta(\mathrm{x}_t,t) - \nabla \log q(\mathrm{x}_t|\mathrm{x}_0)||_2^2 \right], \end{align}\)</p> <p>where \(\lambda_t\) are some constants.</p> <hr/> <h2 id="matching-marginal-distributions">Matching Marginal Distributions</h2> <h3 id="forward-sde">Forward SDE</h3> <p>For pre-defined function \(f:\mathbb{R}^{h\times w \times 3}\times \mathbb{R} \rightarrow \mathbb{R}^{h\times w \times 3}\) and \(g:\mathbb{R} \rightarrow \mathbb{R}\), a forward SDE perturbs the data with Gaussian noise by \(\begin{align} d\mathrm{x}_t = f(\mathrm{x}_t,t)dt + g(t)d\mathrm{w}_t, ~~\text{and}~~ \mathrm{x}_0 \sim \mathrm{P}_{data}, \end{align}\)</p> <p>where \(\mathrm{w}_t\) is Brownian process.</p> <p>If \(\{\mathrm{x}_t\}_{t=0}^T\) is a solution of the forward SDE, it can be treated as a sample from the joint distribution \(\{p_t\}_{t=0}^T\). However, learning joint distribution is difficult and our interest is only \(\mathrm{x}_0\), not \(\{\mathrm{x}_t\}_{t=0}^T\). Therefore, it suffices to consider weakened objective, learning how marginal distributions evolve as \(t\) changes. The evolution of the marginal distributions is goverened by the <strong>Fokker-Plank equation</strong>: \(\begin{align} \partial_t p_t = - \nabla_x (f \cdot p_t ) + \frac{1}{2} \mathrm{tr}(g^T ~\nabla_x^2p_t~ g). \end{align}\)</p> <h3 id="backward-sdeode">Backward SDE/ODE</h3> <p>Following backward SDE and ODE are known to have the same marginal distributions: \(\begin{align} &amp;d\mathrm{x}_t = \left[ f(\mathrm{x}_t,t)dt - g^2(t) \nabla \log p_t(\mathrm{x}_t) \right]dt + g(t)d\bar{\mathrm{w}}_t , ~~\text{and}~~ \mathrm{x}_T \sim \mathcal{N}(\mathrm{0}, \mathrm{I}), \\ &amp;d\mathrm{x}_t = \left[ f(\mathrm{x}_t,t)dt - \frac{1}{2} g^2(t) \nabla \log p_t(\mathrm{x}_t) \right]dt , ~~\text{and}~~ \mathrm{x}_T \sim \mathcal{N}(\mathrm{0}, \mathrm{I}), \end{align}\)</p> <p>where \(\bar{\mathrm{w}}_t\) is the reverse-time Brownian motion. </p> <p>Since \(f(\cdot, \cdot)\) and \(g(\cdot)\) are known, the only unknown component in backward SDE/ODE is \(\nabla \log p_t (\cdot)\) which is also known as a score function. The score function is parametrized by neural network, \(s_\theta(\mathrm{x}_t,t)\).</p> <h3 id="learning-score-function">Learning Score Function</h3> <p>Since we parametrized the score function with the neural network, we can consider a loss function of \(\begin{align} \int_{0}^{T} \lambda_t \mathbb{E}_{\mathrm{x}_t} \left[ ||s_\theta(\mathrm{x}_t,t) - \nabla \log p_t(\mathrm{x}_t)||_2^2 \right] dt, \end{align}\)</p> <p>where \(\lambda_t\) are some constants. Note that \(\nabla\log p_t(\mathrm{x}_t)\) is intractable and with some tricks, the loss function changes into tractable form: \(\begin{align} \int_{0}^{T} \lambda_t \mathbb{E}_{\mathrm{x}_0}\mathbb{E}_{\mathrm{x}_{t}|\mathrm{x}_{0}} \left[ ||s_\theta(\mathrm{x}_t,t) - \nabla \log p_{t|0}(\mathrm{x}_t|\mathrm{x}_0)||_2^2 \right] dt. \end{align}\)</p>]]></content><author><name>Junoh Kang</name></author><category term="deep-learning"/><category term="paper-review"/><summary type="html"><![CDATA[A review of two papers, Denoising diffusion probabilistic models and Score-Based Generative Modeling through Stochastic Differential Equations. This post focuses on theoretical backgrounds of diffusion models, rather than implementations.]]></summary></entry></feed>